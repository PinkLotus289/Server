import os
import json
import time
import logging
from multiprocessing import Process, Queue

from httpx import ProxyError

from .fetcher import IaaIFetcher
from .parser import parse_items
from .utils import sleep_random

# –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤ –≤–Ω—É—Ç—Ä–∏ parser/
BASE_DIR = os.path.dirname(__file__)
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)


def setup_logger(keyword: str) -> logging.Logger:
    logger = logging.getLogger(keyword)
    logger.setLevel(logging.INFO)
    if not logger.handlers:
        fmt = logging.Formatter("%(asctime)s [%(name)s] %(levelname)s: %(message)s")
        sh = logging.StreamHandler()
        sh.setFormatter(fmt)
        logger.addHandler(sh)
        fh = logging.FileHandler(os.path.join(LOG_DIR, f"{keyword}.log"), encoding="utf-8")
        fh.setFormatter(fmt)
        logger.addHandler(fh)
    return logger


def process_section(
    keyword: str,
    proxy_port: int,
    output_dir: str,
    start_page: int,
    page_size: int,
    logger: logging.Logger
) -> int:
    fetcher = IaaIFetcher(keyword, page_size=page_size, proxy_port=proxy_port)
    dyn_pages = fetcher.start_session()
    logger.info(f"–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {dyn_pages}")

    client = fetcher.build_client()

    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, f"{keyword}_lots.json")

    # –∑–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω–æ–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
    if os.path.exists(output_path):
        with open(output_path, "r", encoding="utf-8") as f:
            all_items = json.load(f)
    else:
        all_items = []

    for page in range(start_page, dyn_pages + 1):
        logger.info(f"–ó–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}/{dyn_pages}")
        html = fetcher.fetch_page(client, page)

        # ==== –Ω–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏ –∫–∞–ø—á–µ ====
        if "captcha" in html.lower() or "incapsula" in html.lower():
            logger.warning(f"–ö–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}, –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–µ—Å—Å–∏–∏")
            # –±—Ä–æ—Å–∞–µ–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã run_section_with_restart –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–ª —Å–µ—Å—Å–∏—é
            raise RuntimeError("Captcha detected")
        # =================================

        items = parse_items(html)
        logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(items)} –ª–æ—Ç–æ–≤")
        all_items.extend(items)

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(all_items, f, ensure_ascii=False, indent=2)
        logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(all_items)} –ª–æ—Ç–æ–≤ ‚Üí {output_path}")

        sleep_random(2, 5)

    logger.info(f"üéâ –í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ({dyn_pages}) –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
    return dyn_pages


def run_section_with_restart(
    keyword: str,
    proxy_port: int,
    output_dir: str,
    page_size: int,
    max_retries: int = 5
) -> str:
    logger = setup_logger(keyword)
    output_path = os.path.join(output_dir, f"{keyword}_lots.json")

    # –≥–æ—Ç–æ–≤–∏–º —Å—Ç–∞—Ä—Ç–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
    if os.path.exists(output_path):
        with open(output_path, "r", encoding="utf-8") as f:
            current = json.load(f)
        done_pages = len(current) // page_size
        start_page = done_pages + 1
        logger.info(f"–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª, —Å—Ç–∞—Ä—Ç —Å {start_page}")
    else:
        start_page = 1

    attempts = 0
    while True:
        try:
            process_section(
                keyword,
                proxy_port,
                output_dir,
                start_page,
                page_size,
                logger
            )
            # –µ—Å–ª–∏ –¥–æ—à–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞ –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π ‚Äî –≤—ã—Ö–æ–¥–∏–º
            break

        except ProxyError as e:
            logger.error(f"ProxyError –Ω–∞ —Ä–∞–∑–¥–µ–ª–µ ¬´{keyword}¬ª: {e}")
            logger.error("–ü—Ä–æ–∫—Å–∏ —Ç—Ä–µ–±—É–µ—Ç –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º.")
            break

        except Exception as e:
            attempts += 1
            logger.exception(f"–°–±–æ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {start_page}: {e}")

            if attempts >= max_retries:
                logger.error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ {max_retries} –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –¥–ª—è ¬´{keyword}¬ª, –≤—ã—Ö–æ–¥–∏–º.")
                break

            # –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º start_page –ø–æ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É –ø—Ä–æ–≥—Ä–µ—Å—Å—É
            if os.path.exists(output_path):
                with open(output_path, "r", encoding="utf-8") as f:
                    current = json.load(f)
                done_pages = len(current) // page_size if current else 0
                start_page = done_pages + 1
            else:
                start_page = 1

            logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ {attempts}/{max_retries}. –†–µ—Å—Ç–∞—Ä—Ç —Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã {start_page} —á–µ—Ä–µ–∑ 5 —Å–µ–∫")
            time.sleep(5)

    return output_path



def worker(keyword: str, proxy_port: int, output_dir: str, page_size: int, queue: Queue):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ–∫—Ü–∏—é –∏ –∫–ª–∞–¥—ë—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–ø—É—Ç—å –∫ JSON) –≤ –æ—á–µ—Ä–µ–¥—å.
    """
    try:
        result = run_section_with_restart(keyword, proxy_port, output_dir, page_size)
        queue.put(result)
    except Exception as e:
        setup_logger(keyword).exception(f"–§–∞—Ç–∞–ª—å–Ω—ã–π —Å–±–æ–π —Ä–∞–∑–¥–µ–ª–∞: {e}")


def main():
    cfg_path = os.path.join(BASE_DIR, "sections.json")
    cfg = json.load(open(cfg_path, "r", encoding="utf-8"))
    sections   = cfg.get("sections", [])
    output_dir = cfg.get("output_dir", "JSONs")
    page_size  = cfg.get("page_size", 100)

    # –æ—á–µ—Ä–µ–¥—å –¥–ª—è —Å–±–æ—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    queue = Queue()
    processes = []

    # —Å—Ç–∞—Ä—Ç—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ –∫–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª
    for sec in sections:
        p = Process(
            target=worker,
            args=(sec["keyword"], sec["proxy_port"], output_dir, page_size, queue),
            name=sec["keyword"]
        )
        p.start()
        setup_logger(sec["keyword"]).info(f"Started process pid={p.pid}")
        processes.append(p)

    # –∂–¥—ë–º –ø–æ–∫–∞ –≤—Å–µ –∑–∞–≤–µ—Ä—à–∞—Ç—Å—è
    for p in processes:
        p.join()
        setup_logger(p.name).info(f"Process {p.name} pid={p.pid} exited with code={p.exitcode}")

    # —Å–æ–±–∏—Ä–∞–µ–º –ø—É—Ç–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
    results = []
    while not queue.empty():
        results.append(queue.get())

    print("–í—Å–µ –∑–∞–¥–∞—á–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã. –§–∞–π–ª—ã:")
    for path in results:
        print(" ", path)


if __name__ == "__main__":
    main()
